{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68276bd-c258-441f-95c4-23a26b98d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://objectstore.e2enetworks.net/ai4b-public-nlu-nlg/indic-corp-frozen-for-the-paper-oct-2022/mr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591b5791-e643-4e74-9913-81218d56ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote the first 50000 lines to ./data/mr_50000.txt.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "k = 50000\n",
    "input_file_path = './data/mr.txt'\n",
    "output_file_path = f\"./data/mr_{k}.txt\"\n",
    "\n",
    "# Function to read the first k lines from the input file and write them to the output file\n",
    "def read_and_write_first_k_lines(input_file, output_file, num_lines=1000):\n",
    "    try:\n",
    "        with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "            for i in range(num_lines):\n",
    "                line = infile.readline()\n",
    "                if not line:  # End of file reached before 1000 lines\n",
    "                    break\n",
    "                outfile.write(line)\n",
    "        print(f\"Successfully wrote the first {num_lines} lines to {output_file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function\n",
    "read_and_write_first_k_lines(input_file_path, output_file_path, k)\n",
    "\n",
    "data_file = output_file_path\n",
    "with open(data_file, 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78c3a3c-3c1c-4fd6-8423-60641295abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041670\n",
      "140310\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuations(word):\n",
    "    return word.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Create consecutive pairs\n",
    "all_words = []\n",
    "for line in lines:\n",
    "    if line.strip() != \"\":\n",
    "        words = line.split(\" \")\n",
    "        # Remove blank words\n",
    "        words = [remove_punctuations(word.strip()) for word in words if word.strip() != \"\" ]\n",
    "        all_words.extend(words)\n",
    "\n",
    "all_words  = ['sos'] + all_words + ['eos']\n",
    "print(len(all_words))\n",
    "print(len(list(set(all_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886dfce0-7b03-451d-8a3a-7646bb70b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140310\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "_ = [all_words.extend([word1, word2]) for word1, word2 in word_pairs]\n",
    "distinct_words = list(set(all_words))\n",
    "\n",
    "word_to_i = {word: i for i, word in enumerate(distinct_words)}\n",
    "i_to_word = {i: word for word, i in word_to_i.items()}\n",
    "print(len(distinct_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe7672b-99bc-444d-a067-b727c851af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_words)=288716\n",
      "len(distinct_words)=9180\n"
     ]
    }
   ],
   "source": [
    "# The Number of words is too damn high. Let's filter out the ones which occurs only once\n",
    "\n",
    "word_pairs_indexed = [(word_to_i[word1], word_to_i[word2]) for word1, word2 in word_pairs]\n",
    "high_freq_pairs = [x for x, freq in freq_dict.items() if freq > 20]\n",
    "\n",
    "# Hack to select from large word pairs, store sum of their indexes. This will give some extra, but that's okay\n",
    "high_freq_pairs_key = [word_to_i[word1] + word_to_i[word2] for word1, word2 in high_freq_pairs]\n",
    "high_freq_pairs_key = set(high_freq_pairs_key)\n",
    "\n",
    "freq_word_pairs = []\n",
    "for word1, word2 in word_pairs:\n",
    "    if (word_to_i[word1] + word_to_i[word2]) in high_freq_pairs_key:\n",
    "        freq_word_pairs.extend([(word1, word2)])\n",
    "all_words = []\n",
    "_ = [all_words.extend([word1, word2]) for word1, word2 in freq_word_pairs]\n",
    "distinct_words = list(set(all_words))\n",
    "print(f\"{len(all_words)=}\")\n",
    "print(f\"{len(distinct_words)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6d5373-20d1-447e-a1ce-407839f12433",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_i = {word: i for i, word in enumerate(distinct_words)}\n",
    "i_to_word = {i: word for word, i in word_to_i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bab983-df03-4891-9317-50ed1f649926",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 3\n",
    "for line in lines[:10]:\n",
    "    if line.strip() != \"\":\n",
    "        words = line.split(\" \")\n",
    "        # Remove blank words\n",
    "        words = [word.strip() for word in words if word.strip() != \"\" ]\n",
    "        if len(words) <= context:\n",
    "            # Skip since too few words in the sentence\n",
    "            break\n",
    "        all_words.extend(words)\n",
    "        # Start sos and eos character\n",
    "        words_augmented  = ['sos'] + words + ['eos']\n",
    "        for word1, word2 in zip(words_augmented, words_augmented[1:]):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
